# Video Captioning

- [2015 ICCV] **Sequence to Sequence: Video to Text**, [[paper]](http://www.cs.utexas.edu/users/ml/papers/venugopalan.iccv15.pdf), [[bibtex]](/Bibtex/Sequence%20to%20Sequence%20â€“%20Video%20to%20Text.bib), [[homepage]](https://vsubhashini.github.io/s2vt.html), sources: [[vsubhashini/caffe/examples/s2vt]](https://github.com/vsubhashini/caffe/tree/recurrent/examples/s2vt).
- [2017 ICCV] **Dense-Captioning Events in Videos**, [[paper]](https://arxiv.org/pdf/1705.00754.pdf), [[bibtex]](/Bibtex/Dense-Captioning%20Events%20in%20Videos.bib), [[homepage]](https://cs.stanford.edu/people/ranjaykrishna/densevid/), source: [[ranjaykrishna/densevid_eval]](https://github.com/ranjaykrishna/densevid_eval).
- [2017 ArXiv] **Multi-Task Video Captioning with Video and Entailment Generation**, [[paper]](https://arxiv.org/pdf/1704.07489.pdf), [[bibtex]](/Bibtex/Multi-Task%20Video%20Captioning%20with%20Video%20and%20Entailment%20Generation.bib).
- [2018 CVPR] **Bidirectional Attentive Fusion with Context Gating for Dense Video Captioning**, [[paper]](https://arxiv.org/pdf/1804.00100.pdf), [[bibtex]](/Bibtex/Bidirectional%20Attentive%20Fusion%20with%20Context%20Gating%20for%20Dense%20Video%20Captioning.bib), sources: [[JaywongWang/DenseVideoCaptioning]](https://github.com/JaywongWang/DenseVideoCaptioning).
- [2018 CVPR] **End-to-End Dense Video Captioning with Masked Transformer**, [[paper]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhou_End-to-End_Dense_Video_CVPR_2018_paper.pdf), [[bibtex]](/Bibtex/End-to-End%20Dense%20Video%20Captioning%20with%20Masked%20Transformer.bib), sources: [[salesforce/densecap]](https://github.com/salesforce/densecap).
- [2018 CVPR] **Finding It: Weakly-Supervised Reference-Aware Visual Grounding in Instructional Videos**, [[paper]](http://vision.stanford.edu/pdf/huang-buch-2018cvpr), [[bibtex]](/Bibtex/Finding%20It%20-%20Weakly-Supervised%20Reference-Aware%20Visual%20Grounding%20in%20Instructional%20Videos.bib), [[supplementary]](https://finding-it.github.io/finding-it-suppmat.pdf), [[poster]](https://drive.google.com/file/d/1uvnw6VDn0r1nS3ePyFKaCbEx5GZw1ZEy/view), [[homepage]](https://finding-it.github.io), [[youtube]](https://www.youtube.com/watch?v=GBo4sFNzhtU&feature=youtu.be&t=1366).
- [2018 NeurIPS] **Weakly Supervised Dense Event Captioning in Videos**, [[paper]](https://papers.nips.cc/paper/7569-weakly-supervised-dense-event-captioning-in-videos.pdf), [[bibtex]](/Bibtex/Weakly%20Supervised%20Dense%20Event%20Captioning%20in%20Videos.bib), sources: [[XgDuan/WSDEC]](https://github.com/XgDuan/WSDEC).
- [2019 WACV] **Joint Event Detection and Description in Continuous Video Streams**, [[paper]](http://www.boyangli.co/paper/huijuanxu-wacv-2019.pdf), [[bibtex]](/Bibtex/Joint%20Event%20Detection%20and%20Description%20in%20Continuous%20Video%20Streams.bib), sources: [[VisionLearningGroup/JEDDi-Net]](https://github.com/VisionLearningGroup/JEDDi-Net).
- [2019 CVPR] **Grounded Video Description**, [[paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhou_Grounded_Video_Description_CVPR_2019_paper.pdf), [[bibtex]](/Bibtex/Grounded%20Video%20Description.bib), sources: [[facebookresearch/ActivityNet-Entities]](https://github.com/facebookresearch/ActivityNet-Entities), [[facebookresearch/grounded-video-description]](https://github.com/facebookresearch/grounded-video-description).
- [2019 CSUR] **Video Description: A Survey of Methods, Datasets, and Evaluation Metrics**, [[paper]](https://arxiv.org/pdf/1806.00186.pdf), [[bibtex]](/Bibtex/Video%20Description%20-%20A%20Survey%20of%20Methods%20Datasets%20and%20Evaluation%20Metrics.bib).
- [2019 ACL] **Dense Procedure Captioning in Narrated Instructional Videos**, [[paper]](https://www.aclweb.org/anthology/P19-1641.pdf), [[bibtex]](/Bibtex/Dense%20Procedure%20Captioning%20in%20Narrated%20Instructional%20Videos.bib).
- [2019 ACL] **Multimodal Abstractive Summarization for How2 Videos**, [[paper]](https://www.aclweb.org/anthology/P19-1659.pdf), [[bibtex]](/Bibtex/Multimodal%20Abstractive%20Summarization%20for%20How2%20Videos.bib).
- [2020 ICCV] **VATEX: A Large-Scale, High-Quality Multilingual Dataset for Video-and-Language Research**, [[paper]](http://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_VaTeX_A_Large-Scale_High-Quality_Multilingual_Dataset_for_Video-and-Language_Research_ICCV_2019_paper.pdf), [[bibtex]](/Bibtex/VATEX.bib), [[homepage]](http://vatex.org/main/index.html).
- [2020 ACL] **MART: Memory-Augmented Recurrent Transformer for Coherent Video Paragraph Captioning**, [[paper]](https://www.aclweb.org/anthology/2020.acl-main.233.pdf), [[bibtex]](/Bibtex/MART.bib), sources: [[jayleicn/recurrent-transformer]](https://github.com/jayleicn/recurrent-transformer).